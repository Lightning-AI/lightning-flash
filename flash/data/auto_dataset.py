from typing import Any, Optional, TYPE_CHECKING

import torch
from pytorch_lightning.trainer.states import RunningStage
from pytorch_lightning.utilities.warning_utils import rank_zero_warn

if TYPE_CHECKING:
    from flash.data.data_pipeline import DataPipeline


class AutoDataset(torch.utils.data.Dataset):

    FITTING_STAGES = ("train", "test", "validation")
    STAGES = ("train", "test", "validation", "predict")

    def __init__(self, data: Any, data_pipeline: 'DataPipeline', running_stage: Optional[RunningStage]) -> None:
        super().__init__()
        self.data = data
        self.data_pipeline = data_pipeline
        self._running_stage = None
        self.load_data = None
        self.load_sample = None
        self.running_stage = running_stage

    @property
    def running_stage(self) -> Optional[RunningStage]:
        return self._running_stage

    @running_stage.setter
    def running_stage(self, new_stage):
        self._running_stage = new_stage

        if self._running_stage is not None:
            self._setup(self._running_stage)

    def _setup(self, stage: RunningStage):
        assert stage.value in self.STAGES
        old_load_data = self.load_data.__code__ if self.load_data is not None else None
        self.load_data = getattr(
            self.data_pipeline._preprocess_pipeline, self.data_pipeline._resolve_function_hierarchy('load_data'), stage
        )
        self.load_sample = getattr(
            self.data_pipeline._preprocess_pipeline, self.data_pipeline._resolve_function_hierarchy('load_sample'),
            stage
        )

        # TODO: should we run this again if functions change?
        # IMO we should, since otherwise we cannot guarantee compatibility between load_data and load_sample
        if old_load_data != self.load_data.__code__:
            if old_load_data is not None:
                rank_zero_warn(
                    "The load_data function of the Autogenerated Dataset changed. "
                    "This is not expected! Preloading Data again to ensure compatibility. This may take some time."
                )

            self._processed_data = self.load_data(self.data, dataset=self)

    def __getitem__(self, index: int) -> Any:
        return self.load_sample(self._processed_data[index])

    def __len__(self) -> int:
        return len(self._processed_data)
