{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c histopathologic-cancer-detection --path kaggle --quiet\n",
    "!cd kaggle; unzip -qq histopathologic-cancer-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms as T, models\n",
    "\n",
    "from pl_flash import Flash\n",
    "from pl_flash.vision import ImageClassificationData\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning.metrics.functional as FM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge specific data augmentation. According to the challenge, \"A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label.\" We'll center-crop the images at 49x49px for this reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomVerticalFlip(),\n",
    "    T.RandomRotation(20),\n",
    "    T.CenterCrop((49, 49)),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "valid_transforms = T.Compose([\n",
    "    T.CenterCrop((49, 49)),\n",
    "    T.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `pl_flash.vision.ImageClassificationData` object to load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kaggle/train_labels.csv\")\n",
    "split = int(0.8 * len(df))\n",
    "train_df, val_df = df[:split], df[split:]\n",
    "\n",
    "def filepaths(df):\n",
    "     return [f\"kaggle/train/{_id}.tif\" for _id in df[\"id\"]]   \n",
    "\n",
    "data = ImageClassificationData.from_filepaths(\n",
    "    train_filepaths=filepaths(train_df),\n",
    "    train_labels=list(train_df[\"label\"]),\n",
    "    train_transform=train_transforms,\n",
    "    valid_filepaths=filepaths(val_df),\n",
    "    valid_labels=list(val_df[\"label\"]),\n",
    "    valid_transform=valid_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our model architecture, we'll use a pretrained ResNet, with a few additional linear layers. We can then create a ready-to-train `Flash` model, simply by specifying our loss function, optimizer, learning rate, and desired metric(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "in_features = resnet.fc.in_features\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Sequential(*list(resnet.children())[:-2]), # resnet until pool\n",
    "    nn.AdaptiveMaxPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.BatchNorm1d(in_features),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=in_features, out_features=512),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=512, out_features=2),\n",
    ")\n",
    "\n",
    "def auroc(x, y):\n",
    "    return FM.auroc(F.softmax(x, dim=1)[:, 1], y)\n",
    "\n",
    "flash_model = Flash(\n",
    "    model,\n",
    "    loss=F.cross_entropy,\n",
    "    metrics={\"auroc\": auroc},\n",
    "    optimizer=\"SGD\",\n",
    "    learning_rate=1e-2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our `Flash` model can be used like any other PyTorch Lightning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(gpus=1, max_epochs=20)\n",
    "trainer.fit(flash_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(flash_model, data.val_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUROC 0.9739 ~ top 10% on leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See resulting [TensorBoard.dev](https://tensorboard.dev/experiment/ewumij9mQDy1wg46jegVDw/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
